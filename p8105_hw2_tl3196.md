p8105_hw2_tl3196
================
Tianshu Liu

## Problem 1

``` r
library(tidyverse)
sub_stat_df = 
  read_csv('data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv',
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  mutate(
    entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE)
  ) %>%
  select(line:entry, vending, ada)

sub_stat_df
```

    ## # A tibble: 1,868 × 19
    ##    line     station_…¹ stati…² stati…³ route1 route2 route3 route4 route5 route6
    ##    <chr>    <chr>        <dbl>   <dbl> <chr>  <chr>  <chr>  <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St       40.7   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  2 4 Avenue 25th St       40.7   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  3 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  4 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  5 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  6 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  7 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  8 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  9 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 10 4 Avenue 53rd St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## # … with 1,858 more rows, 9 more variables: route7 <chr>, route8 <chr>,
    ## #   route9 <chr>, route10 <chr>, route11 <chr>, entrance_type <chr>,
    ## #   entry <lgl>, vending <chr>, ada <lgl>, and abbreviated variable names
    ## #   ¹​station_name, ²​station_latitude, ³​station_longitude

There are 1868 × 19 data in the dataset.

The variables contains line, station_name, station_latitude,
station_longitude, route1, route2, route3, route4, route5, route6,
route7, route8, route9, route10, route11, entrance_type, entry, vending,
ada.

This dataset is not tidy.

There are 465 subway stations in NY, 84 of which are ADA compliant.

37.704918 % of the station entrances / exits without vending allow
entrance.

``` r
# clean data with pivot_longer function
clean_sub_stat_df = sub_stat_df %>% 
  pivot_longer(route1:route11,
    names_to = "route_num",
    values_to = "route",
    values_drop_na = TRUE)

# distinct stations serve A train
clean_sub_stat_df %>%
  filter(route == "A") %>% 
  distinct(station_name, line)
```

    ## # A tibble: 60 × 2
    ##    line            station_name                 
    ##    <chr>           <chr>                        
    ##  1 42nd St Shuttle Times Square                 
    ##  2 8 Avenue        125th St                     
    ##  3 8 Avenue        145th St                     
    ##  4 8 Avenue        14th St                      
    ##  5 8 Avenue        168th St - Washington Heights
    ##  6 8 Avenue        175th St                     
    ##  7 8 Avenue        181st St                     
    ##  8 8 Avenue        190th St                     
    ##  9 8 Avenue        34th St                      
    ## 10 8 Avenue        42nd St                      
    ## # … with 50 more rows

``` r
# distinct stations serve A train with ADA
clean_sub_stat_df %>%
   filter(route == "A", ada == "TRUE") %>% 
  distinct(station_name, line)
```

    ## # A tibble: 17 × 2
    ##    line             station_name                 
    ##    <chr>            <chr>                        
    ##  1 8 Avenue         14th St                      
    ##  2 8 Avenue         168th St - Washington Heights
    ##  3 8 Avenue         175th St                     
    ##  4 8 Avenue         34th St                      
    ##  5 8 Avenue         42nd St                      
    ##  6 8 Avenue         59th St                      
    ##  7 8 Avenue         Inwood - 207th St            
    ##  8 8 Avenue         West 4th St                  
    ##  9 8 Avenue         World Trade Center           
    ## 10 Broadway         Times Square-42nd St         
    ## 11 Broadway-7th Ave 59th St-Columbus Circle      
    ## 12 Broadway-7th Ave Times Square                 
    ## 13 Canarsie         8th Av                       
    ## 14 Franklin         Franklin Av                  
    ## 15 Fulton           Euclid Av                    
    ## 16 Fulton           Franklin Av                  
    ## 17 Rockaway         Howard Beach

## Problem 2

Import datasets from `Trash Wheel Collection Data.xlsx` file, and clean
them.

``` r
library(readxl)
mr_trash_whl = read_excel(
  "./data/Trash Wheel Collection Data.xlsx",
  sheet = 1,
  range = cell_cols("A:N"),
  skip = 1,
  na = ""
  ) %>%
  janitor::clean_names() %>%
  drop_na() %>%
  mutate(
    sports_balls = as.integer(sports_balls)
  )

prof_trash_whl = read_excel(
  "./data/Trash Wheel Collection Data.xlsx",
  sheet = 2,
  range = cell_cols("A:M"),
  skip = 1,
  na = ""
  ) %>%
  janitor::clean_names() %>%
  drop_na() %>%
  mutate(
    sports_balls = NA
  )
```

Add a column `trash_wheel` to keep track of the dumpster comes from
which trash wheel, and combine two datasets to the new dataset
`trash_whl`.

``` r
trash_whl = rbind(
  mr_trash_whl %>% 
    mutate(
      trash_wheel = "mr_trash_wheel"
    ), 
  prof_trash_whl %>% 
    mutate(
      trash_wheel = "prof_trash_wheel"
    )
  ) %>%
  relocate(trash_wheel) %>%
  select(-dumpster)

trash_whl
```

    ## # A tibble: 568 × 14
    ##    trash_wheel   month year  date                weigh…¹ volum…² plast…³ polys…⁴
    ##    <chr>         <chr> <chr> <dttm>                <dbl>   <dbl>   <dbl>   <dbl>
    ##  1 mr_trash_whe… May   2014  2014-05-16 00:00:00    4.31      18    1450    1820
    ##  2 mr_trash_whe… May   2014  2014-05-16 00:00:00    2.74      13    1120    1030
    ##  3 mr_trash_whe… May   2014  2014-05-16 00:00:00    3.45      15    2450    3100
    ##  4 mr_trash_whe… May   2014  2014-05-17 00:00:00    3.1       15    2380    2730
    ##  5 mr_trash_whe… May   2014  2014-05-17 00:00:00    4.06      18     980     870
    ##  6 mr_trash_whe… May   2014  2014-05-20 00:00:00    2.71      13    1430    2140
    ##  7 mr_trash_whe… May   2014  2014-05-21 00:00:00    1.91       8     910    1090
    ##  8 mr_trash_whe… May   2014  2014-05-28 00:00:00    3.7       16    3580    4310
    ##  9 mr_trash_whe… June  2014  2014-06-05 00:00:00    2.52      14    2400    2790
    ## 10 mr_trash_whe… June  2014  2014-06-11 00:00:00    3.76      18    1340    1730
    ## # … with 558 more rows, 6 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, and abbreviated variable names
    ## #   ¹​weight_tons, ²​volume_cubic_yards, ³​plastic_bottles, ⁴​polystyrene

``` r
# calculate total weight of trash collected by Mr. Trash Wheel
mr_trash_weight = sum(
  trash_whl %>%
  filter(trash_wheel == 'mr_trash_wheel') %>%
  select(weight_tons)
  )

# calculate total weight of trash collected by Professor Trash Wheel
prof_trash_weight = sum(
  trash_whl %>%
  filter(trash_wheel == 'prof_trash_wheel') %>%
  select(weight_tons)
  )

# calculate total number of sports balls collected by Mr. Trash Wheel in 2020
mr_sports_ball_2020 = sum(
  trash_whl %>%
  filter(trash_wheel == 'mr_trash_wheel', year == 2020) %>%
  select(sports_balls)
)
```

This data set displays the trash record collected by `Mr. Trash Wheel`
and `Professor Trash Wheel` in every dumpster. The combined data set is
`568`×`14`.

Each record in the combined data set represents a dumpster collected by
a trash wheel. Among `568` dumpsters, `486` dumpsters come from
Mr. Trash Wheel, and `82` dumpsters come from Professor Trash Wheel.

The variables in the combined data set are
`trash_wheel, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags, sports_balls, homes_powered`.
Variable `trash_wheel` indicates which trash wheel the record comes
from. Variable `month, year, date` introduces the date of a dumpster.
The rest variables introduce the statistical information of each
dumpster.

Mr and Professor Trash Wheel have collected `1721.52` tons of trash in
total. Among them, Mr. Trash Wheel has collected `1558.98` tons of
trash, and Professor Trash Wheel has collected `162.54` tons of trash.

Mr. Trash Wheel has totally collected `856` sports balls in `2020`.

## Problem 3

First, clean the data in pols-month.csv.

``` r
# First, clean the data in pols-month.csv.
pols_df = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(col = mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>%
  arrange(year, month) %>%
  mutate(
    month = month.name[.$month],
    president = ifelse(prez_gop, "gop", "dem")
  )%>%
    select(-day, -prez_gop, -prez_dem) %>%
  relocate(president, .after = month)

pols_df
```

    ## # A tibble: 822 × 9
    ##     year month     president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ##    <int> <chr>     <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 January   dem            23      51     253      23      45     198
    ##  2  1947 February  dem            23      51     253      23      45     198
    ##  3  1947 March     dem            23      51     253      23      45     198
    ##  4  1947 April     dem            23      51     253      23      45     198
    ##  5  1947 May       dem            23      51     253      23      45     198
    ##  6  1947 June      dem            23      51     253      23      45     198
    ##  7  1947 July      dem            23      51     253      23      45     198
    ##  8  1947 August    dem            23      51     253      23      45     198
    ##  9  1947 September dem            23      51     253      23      45     198
    ## 10  1947 October   dem            23      51     253      23      45     198
    ## # … with 812 more rows

Second, clean the data in snp.csv.

``` r
# Second, clean the data in snp.csv. 
snp_df = read_csv("./data/fivethirtyeight_datasets/snp.csv")  %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day","year"), sep = "/", convert = TRUE) %>%
  mutate(year = ifelse(year>22, year + 1900, year + 2000)) %>%
  arrange(year, month) %>%
  mutate(month = month.name[.$month]) %>%
  select(-day) %>%
  relocate(year, month)

snp_df
```

    ## # A tibble: 787 × 3
    ##     year month     close
    ##    <dbl> <chr>     <dbl>
    ##  1  1950 January    17.0
    ##  2  1950 February   17.2
    ##  3  1950 March      17.3
    ##  4  1950 April      18.0
    ##  5  1950 May        18.8
    ##  6  1950 June       17.7
    ##  7  1950 July       17.8
    ##  8  1950 August     18.4
    ##  9  1950 September  19.5
    ## 10  1950 October    19.5
    ## # … with 777 more rows

Third, clean the data in unemployment.csv.

``` r
# Third, clean the data in unemployment.csv.
unemploy_df = 
  read_csv(
  "./data/fivethirtyeight_datasets/unemployment.csv",
  skip = 1,
  col_names = c("year", 1:12)) %>%
  janitor::clean_names() %>%
  pivot_longer(
    "x1":"x12", 
    names_to = "month", 
    values_to = "perc_of_unem", 
    names_prefix = "x",
    names_transform = list(month = as.numeric)) %>%
  arrange(year, month) %>%
  mutate(month = month.name[.$month]) 

unemploy_df
```

    ## # A tibble: 816 × 3
    ##     year month     perc_of_unem
    ##    <dbl> <chr>            <dbl>
    ##  1  1948 January            3.4
    ##  2  1948 February           3.8
    ##  3  1948 March              4  
    ##  4  1948 April              3.9
    ##  5  1948 May                3.5
    ##  6  1948 June               3.6
    ##  7  1948 July               3.6
    ##  8  1948 August             3.9
    ##  9  1948 September          3.8
    ## 10  1948 October            3.7
    ## # … with 806 more rows

Left join 3 dfs.

``` r
# Left join 3 dfs
left_join_df = pols_df %>%
  left_join(snp_df) %>%
  left_join(unemploy_df)

left_join_df
```

    ## # A tibble: 822 × 11
    ##     year month     presi…¹ gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem close
    ##    <dbl> <chr>     <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ##  1  1947 January   dem          23      51     253      23      45     198    NA
    ##  2  1947 February  dem          23      51     253      23      45     198    NA
    ##  3  1947 March     dem          23      51     253      23      45     198    NA
    ##  4  1947 April     dem          23      51     253      23      45     198    NA
    ##  5  1947 May       dem          23      51     253      23      45     198    NA
    ##  6  1947 June      dem          23      51     253      23      45     198    NA
    ##  7  1947 July      dem          23      51     253      23      45     198    NA
    ##  8  1947 August    dem          23      51     253      23      45     198    NA
    ##  9  1947 September dem          23      51     253      23      45     198    NA
    ## 10  1947 October   dem          23      51     253      23      45     198    NA
    ## # … with 812 more rows, 1 more variable: perc_of_unem <dbl>, and abbreviated
    ## #   variable name ¹​president

The pols dataset contains `822` records from `1947` to `2015`. The data
includes `9` variables, they are
`year, month, president, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem`.

The snp dataset contains `787` records from `1950` to `2015`. The data
includes `3` variables, they are `year, month, close`.

The unemployment dataset contains `816` records from `1948` to `2015`.
The data includes `3` variables, they are `year, month, perc_of_unem`.

After left-joining, the joined dataset contains `822` records from
`1947` to `2015`. The dataset includes `11` variables, they are
`year, month, president, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, close, perc_of_unem`.

The function `left_join` effectively helps merge datasets and maintain
all the record of dates in the first dataset which is `pol_df`. However,
for the dates that do not exist in the last two datasets, the data in
the column `close, perc_of_unem` remains `NA`, which is not good for
subsequent use. Thus, try `inner_join` to join these three datasets.

``` r
# Inner join 3 dfs
inner_join_df = pols_df %>%
  inner_join(snp_df) %>%
  inner_join(unemploy_df)

inner_join_df
```

    ## # A tibble: 786 × 11
    ##     year month     presi…¹ gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem close
    ##    <dbl> <chr>     <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ##  1  1950 January   dem          18      44     177      29      57     269  17.0
    ##  2  1950 February  dem          18      44     177      29      57     269  17.2
    ##  3  1950 March     dem          18      44     177      29      57     269  17.3
    ##  4  1950 April     dem          18      44     177      29      57     269  18.0
    ##  5  1950 May       dem          18      44     177      29      57     269  18.8
    ##  6  1950 June      dem          18      44     177      29      57     269  17.7
    ##  7  1950 July      dem          18      44     177      29      57     269  17.8
    ##  8  1950 August    dem          18      44     177      29      57     269  18.4
    ##  9  1950 September dem          18      44     177      29      57     269  19.5
    ## 10  1950 October   dem          18      44     177      29      57     269  19.5
    ## # … with 776 more rows, 1 more variable: perc_of_unem <dbl>, and abbreviated
    ## #   variable name ¹​president

After inner_joining, the joined dataset contains `786` records from
`1950` to `2015`, which only contains records whose date exists in all
three datasets. The dataset still includes `11` variables, they are
`year, month, president, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, close, perc_of_unem`.
